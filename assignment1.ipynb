{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "403606ad-14f3-44f1-abb5-9c3ec9a69219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting scikit-surprise\n",
      "  Downloading scikit_surprise-1.1.4.tar.gz (154 kB)\n",
      "     ---------------------------------------- 0.0/154.4 kB ? eta -:--:--\n",
      "     ------- ----------------------------- 30.7/154.4 kB 640.0 kB/s eta 0:00:01\n",
      "     -------------------------------------  153.6/154.4 kB 2.3 MB/s eta 0:00:01\n",
      "     -------------------------------------- 154.4/154.4 kB 1.8 MB/s eta 0:00:00\n",
      "  Installing build dependencies: started\n",
      "  Installing build dependencies: finished with status 'done'\n",
      "  Getting requirements to build wheel: started\n",
      "  Getting requirements to build wheel: finished with status 'done'\n",
      "  Preparing metadata (pyproject.toml): started\n",
      "  Preparing metadata (pyproject.toml): finished with status 'done'\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\alienware\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.4.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\alienware\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.26.4)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\alienware\\anaconda3\\lib\\site-packages (from scikit-surprise) (1.13.1)\n",
      "Building wheels for collected packages: scikit-surprise\n",
      "  Building wheel for scikit-surprise (pyproject.toml): started\n",
      "  Building wheel for scikit-surprise (pyproject.toml): finished with status 'done'\n",
      "  Created wheel for scikit-surprise: filename=scikit_surprise-1.1.4-cp311-cp311-win_amd64.whl size=1298159 sha256=d0adfd4d47cce650e523bc4663fce9a2908097eabd233d0fab4e40ff607dda2e\n",
      "  Stored in directory: c:\\users\\alienware\\appdata\\local\\pip\\cache\\wheels\\2a\\8f\\6e\\7e2899163e2d85d8266daab4aa1cdabec7a6c56f83c015b5af\n",
      "Successfully built scikit-surprise\n",
      "Installing collected packages: scikit-surprise\n",
      "Successfully installed scikit-surprise-1.1.4\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-surprise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "301bf995",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5.1\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "from collections import defaultdict\n",
    "import math\n",
    "import scipy.optimize\n",
    "from sklearn import svm\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np\n",
    "import string\n",
    "import random\n",
    "import string\n",
    "from sklearn import linear_model\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "print(torch.__version__)\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from surprise import Dataset, Reader, SVDpp\n",
    "from surprise.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "31cab31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "33f967ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assertFloat(x):\n",
    "    assert type(float(x)) == float\n",
    "\n",
    "def assertFloatList(items, N):\n",
    "    assert len(items) == N\n",
    "    assert [type(float(x)) for x in items] == [float]*N"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3e25a33f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readGz(path):\n",
    "    for l in gzip.open(path, 'rt'):\n",
    "        yield eval(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f88efc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()\n",
    "    for l in f:\n",
    "        u,b,r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u,b,r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2f2db193-3a34-43ea-ba41-2f50ca255d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# assigment 1 Read prediction: Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92a74217-dde5-4eb0-8601-8b94d065a54b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_interactions(file_path):\n",
    "    for user, book, rating in readCSV(file_path):\n",
    "        yield user, book, int(rating)\n",
    "\n",
    "# Initialize data structures\n",
    "data = []\n",
    "book_set = set()\n",
    "user_books = defaultdict(set)\n",
    "book_users = defaultdict(set)\n",
    "user_id_map = {}\n",
    "book_id_map = {}\n",
    "\n",
    "# Read data and build mappings\n",
    "for user, book, rating in read_interactions(\"train_Interactions.csv.gz\"):\n",
    "    data.append((user, book, rating))\n",
    "    book_set.add(book)\n",
    "    user_books[user].add(book)\n",
    "    book_users[book].add(user)\n",
    "    if user not in user_id_map:\n",
    "        user_id_map[user] = len(user_id_map)\n",
    "    if book not in book_id_map:\n",
    "        book_id_map[book] = len(book_id_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f3e53283-676f-4920-8379-37d9414dcde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shuffle data\n",
    "random.shuffle(data)\n",
    "\n",
    "# Split data\n",
    "train_data = data[:160000]\n",
    "extra_train_data = data[160000:180000]\n",
    "validation_data = data[180000:]\n",
    "\n",
    "# Function to get a random book\n",
    "def get_random_book():\n",
    "    return random.choice(list(book_set))\n",
    "\n",
    "# Generate negative samples for validation\n",
    "validation_samples = {}\n",
    "for user, book, _ in validation_data:\n",
    "    validation_samples[(user, book)] = 1  # Positive sample\n",
    "    # Negative sample\n",
    "    neg_book = get_random_book()\n",
    "    while neg_book in user_books[user] or (user, neg_book) in validation_samples:\n",
    "        neg_book = get_random_book()\n",
    "    validation_samples[(user, neg_book)] = 0  # Negative sample\n",
    "\n",
    "# Generate negative samples for extra training\n",
    "extra_samples = {}\n",
    "for user, book, _ in extra_train_data:\n",
    "    extra_samples[(user, book)] = 1  # Positive sample\n",
    "    # Negative sample\n",
    "    neg_book = get_random_book()\n",
    "    while neg_book in user_books[user] or (user, neg_book) in extra_samples:\n",
    "        neg_book = get_random_book()\n",
    "    extra_samples[(user, neg_book)] = 0  # Negative sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "026b1714-f943-4ebd-a7e5-29c4fcb57742",
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_keys_to_indices(pairs):\n",
    "    user_indices = [user_id_map.get(user, 0) for user, _ in pairs]\n",
    "    book_indices = [book_id_map.get(book, 0) for _, book in pairs]\n",
    "    return user_indices, book_indices\n",
    "\n",
    "def cosine_similarity(set1, set2):\n",
    "    intersection_size = len(set1 & set2)\n",
    "    if not set1 or not set2:\n",
    "        return 0\n",
    "    similarity = intersection_size / math.sqrt(len(set1) * len(set2))\n",
    "    return similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1b54edf-d45e-462f-b59f-415c438a64df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BPRModel(torch.nn.Module):\n",
    "    def __init__(self, num_users, num_items, latent_dim, reg_bias, reg_latent):\n",
    "        super(BPRModel, self).__init__()\n",
    "        self.user_factors = torch.nn.Embedding(num_users, latent_dim)\n",
    "        self.item_factors = torch.nn.Embedding(num_items, latent_dim)\n",
    "        self.item_bias = torch.nn.Embedding(num_items, 1)\n",
    "        self.reg_bias = reg_bias\n",
    "        self.reg_latent = reg_latent\n",
    "\n",
    "        # Initialize embeddings\n",
    "        torch.nn.init.normal_(self.user_factors.weight, std=0.01)\n",
    "        torch.nn.init.normal_(self.item_factors.weight, std=0.01)\n",
    "        torch.nn.init.zeros_(self.item_bias.weight)\n",
    "\n",
    "    def forward(self, user_indices, pos_item_indices, neg_item_indices):\n",
    "        user_emb = self.user_factors(user_indices)\n",
    "        pos_item_emb = self.item_factors(pos_item_indices)\n",
    "        neg_item_emb = self.item_factors(neg_item_indices)\n",
    "        pos_item_bias = self.item_bias(pos_item_indices).squeeze()\n",
    "        neg_item_bias = self.item_bias(neg_item_indices).squeeze()\n",
    "\n",
    "        pos_scores = (user_emb * pos_item_emb).sum(dim=1) + pos_item_bias\n",
    "        neg_scores = (user_emb * neg_item_emb).sum(dim=1) + neg_item_bias\n",
    "        loss = -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-10).mean()  # Added epsilon for numerical stability\n",
    "\n",
    "        # Regularization\n",
    "        reg_loss = self.reg_bias * (pos_item_bias.norm(2) + neg_item_bias.norm(2)) / 2\n",
    "        reg_loss += self.reg_latent * (user_emb.norm(2).pow(2).mean() +\n",
    "                                       pos_item_emb.norm(2).pow(2).mean() +\n",
    "                                       neg_item_emb.norm(2).pow(2).mean())\n",
    "        return loss + reg_loss\n",
    "\n",
    "    def predict(self, user_indices, item_indices):\n",
    "        user_emb = self.user_factors(user_indices)\n",
    "        item_emb = self.item_factors(item_indices)\n",
    "        item_bias = self.item_bias(item_indices).squeeze()\n",
    "        scores = (user_emb * item_emb).sum(dim=1) + item_bias\n",
    "        return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8e467305-ef8e-4533-9e6e-13d967d90c88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_bpr(model, optimizer, user_item_pairs):\n",
    "    num_samples = 50000\n",
    "    user_indices = []\n",
    "    pos_item_indices = []\n",
    "    neg_item_indices = []\n",
    "    for _ in range(num_samples):\n",
    "        user, pos_item, _ = random.choice(user_item_pairs)\n",
    "        neg_item = get_random_book()\n",
    "        while neg_item in user_books[user]:\n",
    "            neg_item = get_random_book()\n",
    "        user_indices.append(user_id_map[user])\n",
    "        pos_item_indices.append(book_id_map[pos_item])\n",
    "        neg_item_indices.append(book_id_map[neg_item])\n",
    "    user_indices = torch.tensor(user_indices, dtype=torch.long)\n",
    "    pos_item_indices = torch.tensor(pos_item_indices, dtype=torch.long)\n",
    "    neg_item_indices = torch.tensor(neg_item_indices, dtype=torch.long)\n",
    "\n",
    "    # Validate indices\n",
    "    assertFloatList(user_indices.tolist(), num_samples)\n",
    "    assertFloatList(pos_item_indices.tolist(), num_samples)\n",
    "    assertFloatList(neg_item_indices.tolist(), num_samples)\n",
    "\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    loss = model(user_indices, pos_item_indices, neg_item_indices)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "20f6ad9b-3e53-4ff8-917f-89c8aa1f1a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.7203\n",
      "Validation Accuracy: 0.7376\n",
      "Epoch 10, Loss: 0.6272\n",
      "Validation Accuracy: 0.7527\n",
      "Epoch 20, Loss: 0.5347\n",
      "Validation Accuracy: 0.7538\n",
      "Epoch 30, Loss: 0.4879\n",
      "Validation Accuracy: 0.7538\n",
      "Epoch 40, Loss: 0.4601\n",
      "Validation Accuracy: 0.7541\n",
      "Epoch 50, Loss: 0.4458\n",
      "Validation Accuracy: 0.7547\n"
     ]
    }
   ],
   "source": [
    "num_users = len(user_id_map)\n",
    "num_items = len(book_id_map)\n",
    "latent_dim = 10\n",
    "reg_bias = 0.00013\n",
    "reg_latent = 0.00018\n",
    "bpr_model = BPRModel(num_users, num_items, latent_dim, reg_bias, reg_latent)\n",
    "optimizer = torch.optim.Adam(bpr_model.parameters(), lr=0.03)\n",
    "\n",
    "# Prepare validation data\n",
    "val_user_indices, val_item_indices = map_keys_to_indices(validation_samples.keys())\n",
    "val_user_tensor = torch.tensor(val_user_indices, dtype=torch.long)\n",
    "val_item_tensor = torch.tensor(val_item_indices, dtype=torch.long)\n",
    "\n",
    "for epoch in range(51):\n",
    "    loss = train_bpr(bpr_model, optimizer, train_data)\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "        bpr_model.eval()\n",
    "        with torch.no_grad():\n",
    "            scores = bpr_model.predict(val_user_tensor, val_item_tensor).numpy()\n",
    "        predictions = {pair: int(score > 0) for pair, score in zip(validation_samples.keys(), scores)}\n",
    "        accuracy = sum(predictions[pair] == label for pair, label in validation_samples.items()) / len(validation_samples)\n",
    "        print(f\"Validation Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dc29c879-61f4-4e2e-886d-30f4641c5016",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(fit_intercept=False, max_iter=1000)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;LogisticRegression<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.linear_model.LogisticRegression.html\">?<span>Documentation for LogisticRegression</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>LogisticRegression(fit_intercept=False, max_iter=1000)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(fit_intercept=False, max_iter=1000)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build book popularity\n",
    "book_popularity = defaultdict(int)\n",
    "for _, book, _ in data:\n",
    "    book_popularity[book] += 1\n",
    "\n",
    "def compute_features(pairs):\n",
    "    features = []\n",
    "    for user, book in pairs:\n",
    "        user_books_set = user_books.get(user, set())\n",
    "        item_similarity = [cosine_similarity(book_users.get(other_book, set()), book_users.get(book, set()))\n",
    "                           for other_book in user_books_set if other_book != book]\n",
    "        avg_item_sim = sum(item_similarity) / len(item_similarity) if item_similarity else 0.01\n",
    "        max_item_sim = max(item_similarity) if item_similarity else 0.01\n",
    "\n",
    "        book_users_set = book_users.get(book, set())\n",
    "        user_similarity = [cosine_similarity(user_books.get(other_user, set()), user_books_set)\n",
    "                           for other_user in book_users_set if other_user != user]\n",
    "        avg_user_sim = sum(user_similarity) / len(user_similarity) if user_similarity else 0.01\n",
    "        max_user_sim = max(user_similarity) if user_similarity else 0.01\n",
    "\n",
    "        # BPR score\n",
    "        user_idx = torch.tensor([user_id_map.get(user, 0)], dtype=torch.long)\n",
    "        book_idx = torch.tensor([book_id_map.get(book, 0)], dtype=torch.long)\n",
    "        with torch.no_grad():\n",
    "            bpr_score = bpr_model.predict(user_idx, book_idx).item()\n",
    "\n",
    "        # Validate BPR score\n",
    "        assertFloat(bpr_score)\n",
    "\n",
    "        # Book popularity\n",
    "        popularity = book_popularity.get(book, 0) / 100\n",
    "\n",
    "        # Feature vector\n",
    "        feature_vector = [bpr_score, avg_item_sim, max_item_sim, avg_user_sim, max_user_sim, popularity, 1]\n",
    "        # Validate feature vector\n",
    "        assertFloatList(feature_vector, 7)\n",
    "        features.append(feature_vector)\n",
    "    return features\n",
    "\n",
    "# Prepare training data for logistic regression\n",
    "X_train = compute_features(extra_samples.keys())\n",
    "y_train = list(extra_samples.values())\n",
    "\n",
    "# Validate labels\n",
    "assert all(label in [0, 1] for label in y_train)\n",
    "\n",
    "# Train logistic regression model\n",
    "log_reg = linear_model.LogisticRegression(fit_intercept=False, max_iter=1000)\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "22648fdf-11ea-4fb3-9a7c-9a39e2cde332",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Accuracy after Logistic Regression: 0.9982\n"
     ]
    }
   ],
   "source": [
    "X_val = compute_features(validation_samples.keys())\n",
    "y_val = list(validation_samples.values())\n",
    "y_pred = log_reg.predict(X_val)\n",
    "accuracy = sum(yp == yt for yp, yt in zip(y_pred, y_val)) / len(y_val)\n",
    "print(f\"Validation Accuracy after Logistic Regression: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e259b3a9-a458-4a22-98f7-ce7b75d5fcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read test pairs\n",
    "test_pairs = []\n",
    "with open(\"pairs_Read.csv\", \"r\") as f:\n",
    "    next(f)  # Skip header\n",
    "    for line in f:\n",
    "        user, book = line.strip().split(',')\n",
    "        test_pairs.append((user, book))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "35ea4b17-9378-4645-9514-5041b67bc1e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute features for test data\n",
    "X_test = compute_features(test_pairs)\n",
    "\n",
    "# Validate features\n",
    "for feature_vector in X_test:\n",
    "    assertFloatList(feature_vector, 7)\n",
    "\n",
    "# Predict scores\n",
    "test_scores = log_reg.decision_function(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3c50816-cf87-486b-931a-c4073e46ea7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply thresholding per user\n",
    "def threshold_predictions(pairs, scores):\n",
    "    predictions = {}\n",
    "    user_to_scores = defaultdict(list)\n",
    "    for (user, book), score in zip(pairs, scores):\n",
    "        user_to_scores[user].append((book, score))\n",
    "    for user, items in user_to_scores.items():\n",
    "        items.sort(key=lambda x: x[1], reverse=True)\n",
    "        threshold_score = items[len(items) // 2][1]\n",
    "        for book, score in items:\n",
    "            predictions[(user, book)] = int(score > threshold_score)\n",
    "    return predictions\n",
    "\n",
    "final_predictions = threshold_predictions(test_pairs, test_scores)\n",
    "\n",
    "# Write predictions to file\n",
    "with open(\"predictions_Read.csv\", 'w') as f:\n",
    "    f.write('userID,bookID,prediction\\n')\n",
    "    for user, book in test_pairs:\n",
    "        pred = final_predictions.get((user, book), 0)\n",
    "        f.write(f\"{user},{book},{pred}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ced407e-da55-4753-be6c-f27a274c7810",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rating prediction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9421297f-417d-416f-bbc4-b368551b10f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "train_data = []\n",
    "for user, book, rating in readCSV('train_Interactions.csv.gz'):\n",
    "    train_data.append((user, book, float(rating)))  # Ensure rating is float\n",
    "\n",
    "# Convert to DataFrame\n",
    "df_train = pd.DataFrame(train_data, columns=['userID', 'bookID', 'rating'])\n",
    "\n",
    "# Define the rating scale\n",
    "rating_scale = (df_train['rating'].min(), df_train['rating'].max())\n",
    "\n",
    "# Create a Reader\n",
    "reader = Reader(rating_scale=rating_scale)\n",
    "\n",
    "# Load data into Surprise dataset using the entire df_train\n",
    "data = Dataset.load_from_df(df_train[['userID', 'bookID', 'rating']], reader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ccd7bdcf-632c-42c3-ae8a-fd341369bd62",
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'n_factors': [26, 27, 28, 29, 30],        # Fine-grained around 28\n",
    "    'lr_all': [0.0016, 0.0018, 0.002, 0.0022],  # Finer steps around 0.0018\n",
    "    'n_epochs': [100, 105, 110],              # Slight variation around 105\n",
    "    'reg_bu': [0.14, 0.15, 0.16],             # Narrow range around 0.15\n",
    "    'reg_bi': [0.29, 0.3, 0.31],              # Narrow range around 0.3\n",
    "    'reg_pu': [0.33, 0.35, 0.37],             # Narrow range around 0.35\n",
    "    'reg_qi': [0.73, 0.75, 0.77],             # Narrow range around 0.75\n",
    "    'reg_yj': [0.12, 0.13, 0.14]              # Narrow range around 0.13\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26c0f804-2426-4ee3-975d-3279d1756e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best RMSE: 1.2122368571609419\n",
      "Best params: {'n_factors': 28, 'lr_all': 0.0018, 'n_epochs': 105, 'reg_bu': 0.16, 'reg_bi': 0.3, 'reg_pu': 0.35, 'reg_qi': 0.77, 'reg_yj': 0.13}\n"
     ]
    }
   ],
   "source": [
    "# Perform randomized grid search\n",
    "rs = RandomizedSearchCV(\n",
    "    SVDpp, \n",
    "    param_grid, \n",
    "    measures=['rmse'], \n",
    "    cv=3, \n",
    "    n_jobs=-1, \n",
    "    n_iter=200,  # Adjust based on desired search breadth\n",
    "    random_state=42\n",
    ")\n",
    "rs.fit(data)\n",
    "\n",
    "# Output best score and parameters\n",
    "print(f\"Best RMSE: {rs.best_score['rmse']}\")\n",
    "print(f\"Best params: {rs.best_params['rmse']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "369b78f0-4c90-47d4-a010-728011b9cab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the best parameters\n",
    "best_params = rs.best_params['rmse']\n",
    "\n",
    "# Build the full training set\n",
    "trainset = data.build_full_trainset()\n",
    "\n",
    "# Train the SVDpp model with the best parameters\n",
    "model = SVDpp(\n",
    "    n_factors=best_params['n_factors'],\n",
    "    lr_all=best_params['lr_all'],\n",
    "    n_epochs=best_params['n_epochs'],\n",
    "    reg_bu=best_params['reg_bu'],\n",
    "    reg_bi=best_params['reg_bi'],\n",
    "    reg_pu=best_params['reg_pu'],\n",
    "    reg_qi=best_params['reg_qi'],\n",
    "    reg_yj=best_params['reg_yj']\n",
    ")\n",
    "model.fit(trainset)\n",
    "\n",
    "# Read test pairs\n",
    "test_pairs = []\n",
    "with open('pairs_Rating.csv', 'r') as f:\n",
    "    next(f)  # Skip header\n",
    "    for line in f:\n",
    "        user, book = line.strip().split(',')\n",
    "        test_pairs.append((user, book))\n",
    "\n",
    "# Make predictions\n",
    "with open('predictions_Rating.csv', 'w') as pred_file:\n",
    "    pred_file.write('userID,bookID,prediction\\n')\n",
    "    for user, book in test_pairs:\n",
    "        est = model.predict(user, book).est\n",
    "        pred_file.write(f\"{user},{book},{est}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a48d2ad4-f56e-443e-96bd-5abdbf0104da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c14b35b1-2607-4ee1-a52a-df4443e94f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bi-encoder\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(42)\n",
    "\n",
    "# Determine the device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")\n",
    "\n",
    "# Function to read the CSV file\n",
    "def readCSV(path):\n",
    "    f = gzip.open(path, 'rt')\n",
    "    f.readline()  # Skip the header\n",
    "    for l in f:\n",
    "        u, b, r = l.strip().split(',')\n",
    "        r = int(r)\n",
    "        yield u, b, r\n",
    "\n",
    "# Load all ratings from training data\n",
    "allRatings = []\n",
    "for l in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)\n",
    "\n",
    "# Convert to DataFrame for easier manipulation\n",
    "ratings_df = pd.DataFrame(allRatings, columns=['userID', 'bookID', 'rating'])\n",
    "\n",
    "# Load test data\n",
    "test_df = pd.read_csv(\"pairs_Read.csv\")\n",
    "\n",
    "# Combine users and books from both training and test data\n",
    "all_users = set(ratings_df['userID']).union(set(test_df['userID']))\n",
    "all_books = set(ratings_df['bookID']).union(set(test_df['bookID']))\n",
    "\n",
    "# Create dictionaries for quick lookup\n",
    "books_per_user = defaultdict(set)\n",
    "users_per_book = defaultdict(set)\n",
    "for _, row in ratings_df.iterrows():\n",
    "    u = row['userID']\n",
    "    b = row['bookID']\n",
    "    books_per_user[u].add(b)\n",
    "    users_per_book[b].add(u)\n",
    "\n",
    "# Negative sampling\n",
    "negative_ratio = 1  # Adjust as needed\n",
    "negative_samples = []\n",
    "for u in books_per_user:\n",
    "    read_books = books_per_user[u]\n",
    "    unread_books = all_books - read_books\n",
    "    n_negative = min(len(read_books) * negative_ratio, len(unread_books))\n",
    "    if n_negative > 0:\n",
    "        # Convert unread_books to a list before sampling\n",
    "        negative_books = random.sample(list(unread_books), n_negative)\n",
    "        for b in negative_books:\n",
    "            negative_samples.append((u, b, 0))  # Label 0 for unread books\n",
    "\n",
    "# Positive samples (label 1)\n",
    "positive_samples = [(row['userID'], row['bookID'], 1) for _, row in ratings_df.iterrows()]\n",
    "\n",
    "# Combine samples\n",
    "all_samples = positive_samples + negative_samples\n",
    "samples_df = pd.DataFrame(all_samples, columns=['userID', 'bookID', 'label'])\n",
    "\n",
    "# Shuffle the data\n",
    "samples_df = samples_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Create ID to index mappings\n",
    "user_ids = list(all_users)\n",
    "book_ids = list(all_books)\n",
    "\n",
    "user_to_index = {u: idx for idx, u in enumerate(user_ids)}\n",
    "book_to_index = {b: idx for idx, b in enumerate(book_ids)}\n",
    "\n",
    "num_users = len(user_ids)\n",
    "num_books = len(book_ids)\n",
    "\n",
    "# Prepare input data\n",
    "def prepare_input(df):\n",
    "    user_indices = df['userID'].map(user_to_index).astype(int).values\n",
    "    book_indices = df['bookID'].map(book_to_index).astype(int).values\n",
    "    labels = df['label'].values\n",
    "    return user_indices, book_indices, labels\n",
    "\n",
    "# Split into training and validation sets\n",
    "train_df, val_df = train_test_split(samples_df, test_size=0.2, random_state=42, stratify=samples_df['label'])\n",
    "\n",
    "train_user_indices, train_book_indices, train_labels = prepare_input(train_df)\n",
    "val_user_indices, val_book_indices, val_labels = prepare_input(val_df)\n",
    "\n",
    "# Define the model\n",
    "class BiEncoderModel(nn.Module):\n",
    "    def __init__(self, num_users, num_books, embedding_dim):\n",
    "        super(BiEncoderModel, self).__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_dim)\n",
    "        self.book_embedding = nn.Embedding(num_books, embedding_dim)\n",
    "        \n",
    "        # Initialize embeddings\n",
    "        nn.init.xavier_uniform_(self.user_embedding.weight)\n",
    "        nn.init.xavier_uniform_(self.book_embedding.weight)\n",
    "        \n",
    "    def forward(self, user_indices, book_indices):\n",
    "        user_embeds = self.user_embedding(user_indices)\n",
    "        book_embeds = self.book_embedding(book_indices)\n",
    "        scores = (user_embeds * book_embeds).sum(dim=1)\n",
    "        probs = torch.sigmoid(scores)\n",
    "        return probs\n",
    "\n",
    "embedding_dim = 50  # Adjust as needed\n",
    "model = BiEncoderModel(num_users, num_books, embedding_dim).to(device)\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Prepare DataLoaders\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class InteractionDataset(Dataset):\n",
    "    def __init__(self, user_indices, book_indices, labels):\n",
    "        self.user_indices = torch.LongTensor(user_indices)\n",
    "        self.book_indices = torch.LongTensor(book_indices)\n",
    "        self.labels = torch.FloatTensor(labels)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.user_indices[idx], self.book_indices[idx], self.labels[idx]\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = InteractionDataset(train_user_indices, train_book_indices, train_labels)\n",
    "val_dataset = InteractionDataset(val_user_indices, val_book_indices, val_labels)\n",
    "\n",
    "# Create DataLoaders\n",
    "batch_size = 1024  # Adjust as needed\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 5  # Adjust as needed\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for user_indices, book_indices, labels in train_loader:\n",
    "        user_indices = user_indices.to(device)\n",
    "        book_indices = book_indices.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(user_indices, book_indices)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "    avg_loss = total_loss / len(train_dataset)\n",
    "    \n",
    "    # Validation\n",
    "    model.eval()\n",
    "    total_val_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for user_indices, book_indices, labels in val_loader:\n",
    "            user_indices = user_indices.to(device)\n",
    "            book_indices = book_indices.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(user_indices, book_indices)\n",
    "            loss = criterion(outputs, labels)\n",
    "            total_val_loss += loss.item() * labels.size(0)\n",
    "            preds = (outputs >= 0.5).float()\n",
    "            correct += (preds == labels).sum().item()\n",
    "    avg_val_loss = total_val_loss / len(val_dataset)\n",
    "    accuracy = correct / len(val_dataset)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {avg_loss:.4f}, Val Loss: {avg_val_loss:.4f}, Val Acc: {accuracy:.4f}\")\n",
    "\n",
    "# Prepare test input\n",
    "def prepare_test_input(df):\n",
    "    user_indices = df['userID'].map(user_to_index).astype(int).values\n",
    "    book_indices = df['bookID'].map(book_to_index).astype(int).values\n",
    "    return torch.LongTensor(user_indices), torch.LongTensor(book_indices)\n",
    "\n",
    "test_user_indices, test_book_indices = prepare_test_input(test_df)\n",
    "\n",
    "# Create test DataLoader\n",
    "test_dataset = torch.utils.data.TensorDataset(test_user_indices, test_book_indices)\n",
    "test_loader = DataLoader(test_dataset, batch_size=1024)\n",
    "\n",
    "# Make predictions\n",
    "model.eval()\n",
    "all_predictions = []\n",
    "with torch.no_grad():\n",
    "    for user_indices, book_indices in test_loader:\n",
    "        user_indices = user_indices.to(device)\n",
    "        book_indices = book_indices.to(device)\n",
    "        outputs = model(user_indices, book_indices)\n",
    "        all_predictions.extend(outputs.cpu().tolist())\n",
    "\n",
    "# Convert probabilities to binary labels\n",
    "threshold = 0.5\n",
    "binary_predictions = [1 if pred >= threshold else 0 for pred in all_predictions]\n",
    "\n",
    "# Write predictions to CSV\n",
    "test_df['prediction'] = binary_predictions\n",
    "test_df[['userID', 'bookID', 'prediction']].to_csv('predictions_Read.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ce7aa04a-4f54-41f3-8988-186dbbec757d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Homework 3 code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a5f39ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3b16eab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some data structures that will be useful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "09ac1dc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "allRatings = []\n",
    "for l in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    allRatings.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4717806",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200000"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(allRatings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "942b17bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      userID     bookID  prediction\n",
      "0  u95048695  b80407575         NaN\n",
      "1  u64624839  b22251874         NaN\n",
      "2  u45364671  b59334959         NaN\n",
      "3  u89964247  b96807645         NaN\n",
      "4  u27746462  b93777449         NaN\n",
      "5  u45033856  b02250808         NaN\n",
      "6  u27598419  b12715496         NaN\n",
      "7  u20059243  b74622707         NaN\n",
      "8  u52760220  b33229445         NaN\n",
      "9  u95557022  b55417152         NaN\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"pairs_Read.csv\")\n",
    "print(df.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6fad7606",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('u93397390', 'b52690052', 3),\n",
       " ('u93952353', 'b52355478', 1),\n",
       " ('u09633433', 'b89163374', 0),\n",
       " ('u91366781', 'b78391921', 5),\n",
       " ('u50251394', 'b80097453', 0),\n",
       " ('u98333620', 'b80430178', 3),\n",
       " ('u77448169', 'b59839746', 5),\n",
       " ('u26756934', 'b97033148', 5),\n",
       " ('u05133116', 'b80332084', 4),\n",
       " ('u83823213', 'b21044596', 0)]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "allRatings[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ca3c2a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "ratingsTrain = allRatings[:190000]\n",
    "ratingsValid = allRatings[190000:]\n",
    "ratingsPerUser = defaultdict(list)\n",
    "ratingsPerItem = defaultdict(list)\n",
    "for u,b,r in ratingsTrain:\n",
    "    ratingsPerUser[u].append((b,r))\n",
    "    ratingsPerItem[b].append((u,r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "93959f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Read prediction                                #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "abb17ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copied from baseline code\n",
    "bookCount = defaultdict(int)\n",
    "totalRead = 0\n",
    "\n",
    "for user,book,_ in readCSV(\"train_Interactions.csv.gz\"):\n",
    "    bookCount[book] += 1\n",
    "    totalRead += 1\n",
    "\n",
    "mostPopular = [(bookCount[x], x) for x in bookCount]\n",
    "mostPopular.sort()\n",
    "mostPopular.reverse()\n",
    "\n",
    "return1 = set()\n",
    "count = 0\n",
    "for ic, i in mostPopular:\n",
    "    count += ic\n",
    "    return1.add(i)\n",
    "    if count > totalRead/2: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "80f40789",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7c9eea8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all books in the dataset and create the negative valid set\n",
    "allBooks = set([b for _,b,_ in allRatings])\n",
    "\n",
    "ratingsValidNeg = []\n",
    "for u,b,r in ratingsValid:\n",
    "    bookReadByUser = set([b for b,_ in ratingsPerUser[u]])\n",
    "    unread = list(allBooks - bookReadByUser)\n",
    "    \n",
    "    if unread:\n",
    "        negativeB = random.choice(unread)\n",
    "        ratingsValidNeg.append((u, negativeB, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "80998c65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7177"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combinedValid = ratingsValid + ratingsValidNeg\n",
    "def predict(user, book, mostPopularBooks):\n",
    "    return 1 if book in mostPopularBooks else 0\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for u,b,r in combinedValid:\n",
    "    prediction = predict(u,b,return1)\n",
    "    binary = 0\n",
    "    if r > 0:\n",
    "        binary = 1\n",
    "    if prediction == binary:\n",
    "        correct += 1\n",
    "    total += 1\n",
    "acc1 = correct/total\n",
    "acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8af7b181",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q1'] = acc1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6839df36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1': 0.7199}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "assertFloat(answers['Q1'])\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "50491907",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "87e03b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_accurate_threshold(percentage):\n",
    "    popular_books = set()\n",
    "    count = 0\n",
    "    for ic, i in mostPopular:\n",
    "        count += ic\n",
    "        popular_books.add(i)\n",
    "        if count > totalRead * percentage: break\n",
    "    return popular_books\n",
    "\n",
    "perc = [0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\n",
    "best_threshold = 0\n",
    "best_acc = 0\n",
    "\n",
    "for p in perc:\n",
    "    return1 = most_accurate_threshold(p)\n",
    "    \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for u,b,r in combinedValid:\n",
    "        prediction = predict(u,b,return1)\n",
    "        binary = 0\n",
    "        if r > 0:\n",
    "            binary = 1\n",
    "        if prediction == binary:\n",
    "            correct += 1\n",
    "        total += 1\n",
    "    acc = correct/total\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_threshold = p\n",
    "\n",
    "\n",
    "threshold = best_threshold\n",
    "acc2 = best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "263c16a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1': 0.7199, 'Q2': [0.7, 0.75095]}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q2'] = [threshold, acc2]\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fcb6b96c",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q2'][0])\n",
    "assertFloat(answers['Q2'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b753559d",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "04a6f2e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Jaccard(s1, s2):\n",
    "    numer = len(s1.intersection(s2))\n",
    "    denom = len(s1.union(s2))\n",
    "    if denom == 0:\n",
    "        return 0\n",
    "    return numer / denom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e8cc281",
   "metadata": {},
   "outputs": [],
   "source": [
    "usersPerBook = defaultdict(set)\n",
    "booksPerUser = defaultdict(set)\n",
    "\n",
    "# Create a dictionary that maps each book to its set of readers\n",
    "for u,b,_ in ratingsTrain:\n",
    "    usersPerBook[b].add(u)\n",
    "    booksPerUser[u].add(b)\n",
    "\n",
    "# for u,b,_ in allRatings:\n",
    "#     usersPerBook[b].add(u)\n",
    "    \n",
    "# Prepare the validation set\n",
    "validation_set = [(u,b,1) for u,b,_ in ratingsValid] + ratingsValidNeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64925222",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.004\n",
    "predictions = list()\n",
    "labels = list()\n",
    "for user, book, label in validation_set:\n",
    "    labels.append(label)\n",
    "    similarities = [0]\n",
    "    user_b = {user for user in usersPerBook[book]}\n",
    "    for book_prime in booksPerUser[user]:\n",
    "        user_b_prime = {user for user in usersPerBook[book_prime]}\n",
    "        sim = Jaccard(user_b, user_b_prime)\n",
    "        similarities.append(sim)\n",
    "    if max(similarities) > threshold:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0358f62f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.70575"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrects = [p == l for p, l in zip(predictions, labels)]\n",
    "acc3 = sum(corrects) / len(predictions)\n",
    "acc3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "dcec3ddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# maxJaccard = {}\n",
    "# for u, b, _ in validation_set:\n",
    "#     maxSim = 0\n",
    "#     if b in usersPerBook:\n",
    "#         for b_prime in booksPerUser[u]:\n",
    "#             if b_prime in usersPerBook:\n",
    "#                 sim = Jaccard(usersPerBook[b], usersPerBook[b_prime])\n",
    "#                 if sim > maxSim:\n",
    "#                     maxSim = sim\n",
    "#     maxJaccard[(u, b)] = maxSim\n",
    "# # maxJaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f54131ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# thresholds = [i / 10000 for i in range(0, 200)]  # 0.000 to 0.020 in steps of 0.001\n",
    "\n",
    "# # Store accuracy for each threshold\n",
    "# accuracy_per_threshold = []\n",
    "\n",
    "# for threshold in thresholds:\n",
    "#     correct_predictions = 0\n",
    "#     total_predictions = len(validation_set)\n",
    "\n",
    "#     for u, b, actual_label in validation_set:\n",
    "#         predicted_label = 1 if maxJaccard[(u, b)] >= threshold else 0\n",
    "#         if predicted_label == actual_label:\n",
    "#             correct_predictions += 1\n",
    "#     accuracy = correct_predictions / total_predictions\n",
    "\n",
    "#     accuracy_per_threshold.append({\n",
    "#         'threshold': threshold,\n",
    "#         'accuracy': accuracy\n",
    "#     })\n",
    "\n",
    "# best_performance = max(accuracy_per_threshold, key=lambda x: x['accuracy'])\n",
    "# best_threshold = best_performance['threshold']\n",
    "\n",
    "# print(f\"Best Threshold: {best_threshold}\")\n",
    "# print(f\"Accuracy: {best_performance['accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eac2dd79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.73175"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "threshold_Jaccard = 0.004\n",
    "threshold_popularity = 24\n",
    "predictions = list()\n",
    "labels = list()\n",
    "popularityL = list()\n",
    "for user, book, label in validation_set:\n",
    "    labels.append(label)\n",
    "    similarities = [0]\n",
    "    user_b = {user for user in usersPerBook[book]}\n",
    "    popularity = len(user_b)\n",
    "    popularityL.append(popularity)\n",
    "    for book_prime in booksPerUser[user]:\n",
    "        user_b_prime = {user for user in usersPerBook[book_prime]}\n",
    "        sim = Jaccard(user_b, user_b_prime)\n",
    "        similarities.append(sim)\n",
    "    if max(similarities) > threshold_Jaccard and popularity > threshold_popularity:\n",
    "        predictions.append(1)\n",
    "    else:\n",
    "        predictions.append(0)\n",
    "\n",
    "corrects = [p == l for p, l in zip(predictions, labels)]\n",
    "acc4 = sum(corrects) / len(predictions)\n",
    "acc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2377a5c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(popularityL)[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "83ab0986",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q3'] = acc3\n",
    "answers['Q4'] = acc4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fbdd0c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q3'])\n",
    "assertFloat(answers['Q4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "3e68cbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold_Jaccard = 0.004\n",
    "threshold_popularity = 24\n",
    "popularityL = list()\n",
    "\n",
    "predictions = open(\"predictions_Read.csv\", 'w')\n",
    "for l in open(\"pairs_Read.csv\"):\n",
    "    if l.startswith(\"userID\"):\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',')\n",
    "    # My code starts here\n",
    "\n",
    "    similarities = [0]\n",
    "    user_b = {user for user in usersPerBook[b]}\n",
    "    popularity = len(user_b)\n",
    "    popularityL.append(popularity)\n",
    "    for book_prime in booksPerUser[u]:\n",
    "        user_b_prime = {user for user in usersPerBook[book_prime]}\n",
    "        sim = Jaccard(user_b, user_b_prime)\n",
    "        similarities.append(sim)\n",
    "        \n",
    "    if max(similarities) > threshold_Jaccard and popularity > threshold_popularity:\n",
    "        pred = 1  \n",
    "    else:\n",
    "        pred = 0  # Predict 'not read'\n",
    "\n",
    "    # Write the prediction to the output file\n",
    "    predictions.write(f\"{u},{b},{pred}\\n\")\n",
    "    \n",
    "\n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "97688ca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(popularityL)\n",
    "sorted(popularityL)[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "297b5c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q5'] = \"I confirm that I have uploaded an assignment submission to gradescope\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b3cb95e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert type(answers['Q5']) == str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "bcf70975",
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################################\n",
    "# Rating prediction                              #\n",
    "##################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "af7f3f37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('u47877739', 'b50020691', 4),\n",
       " ('u44286663', 'b17025078', 5),\n",
       " ('u73526619', 'b22925633', 5),\n",
       " ('u39123859', 'b62815615', 0),\n",
       " ('u12786783', 'b99699446', 2),\n",
       " ('u99072969', 'b24832848', 4),\n",
       " ('u84518411', 'b73152433', 2),\n",
       " ('u50827374', 'b41385722', 3),\n",
       " ('u16732033', 'b77335595', 4),\n",
       " ('u24849922', 'b00310513', 5)]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ratingsValid[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "95b960a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d69e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe preprocessing\n",
    "df_train = pd.DataFrame(ratingsTrain, columns=['userID', 'itemID', 'rating'])\n",
    "df_valid = pd.DataFrame(ratingsValid, columns=['userID', 'itemID', 'rating'])\n",
    "\n",
    "df_valid = df_valid[\n",
    "    df_valid['userID'].isin(df_train['userID']) &\n",
    "    df_valid['itemID'].isin(df_train['itemID'])\n",
    "].copy()\n",
    "\n",
    "user_encoder = LabelEncoder()\n",
    "item_encoder = LabelEncoder()\n",
    "\n",
    "# Fit encoders on training data\n",
    "df_train['user_idx'] = user_encoder.fit_transform(df_train['userID'])\n",
    "df_train['item_idx'] = item_encoder.fit_transform(df_train['itemID'])\n",
    "\n",
    "# Transform validation data\n",
    "df_valid['user_idx'] = user_encoder.transform(df_valid['userID'])\n",
    "df_valid['item_idx'] = item_encoder.transform(df_valid['itemID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "499677ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6867473684210528"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alpha = df_train['rating'].mean()\n",
    "alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "d5d4560f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize bias term for every user and item\n",
    "num_users = df_train['user_idx'].nunique()\n",
    "num_items = df_train['item_idx'].nunique()\n",
    "beta_user = np.zeros(num_users)\n",
    "beta_item = np.zeros(num_items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f008444b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training MSE: 1.5851\n",
      "Epoch 2/10, Training MSE: 1.5119\n",
      "Epoch 3/10, Training MSE: 1.4601\n",
      "Epoch 4/10, Training MSE: 1.4209\n",
      "Epoch 5/10, Training MSE: 1.3898\n",
      "Epoch 6/10, Training MSE: 1.3649\n",
      "Epoch 7/10, Training MSE: 1.3460\n",
      "Epoch 8/10, Training MSE: 1.3294\n",
      "Epoch 9/10, Training MSE: 1.3157\n",
      "Epoch 10/10, Training MSE: 1.3032\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "lambda_reg = 1  # reg parameter\n",
    "\n",
    "train_users = df_train['user_idx'].values\n",
    "train_items = df_train['item_idx'].values\n",
    "train_ratings = df_train['rating'].values\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    shuffled_indices = np.arange(len(train_ratings))\n",
    "    np.random.shuffle(shuffled_indices)\n",
    "    \n",
    "    for idx in shuffled_indices:\n",
    "        u = train_users[idx]\n",
    "        i = train_items[idx]\n",
    "        r_ui = train_ratings[idx]\n",
    "        \n",
    "        # make rating predictions\n",
    "        pred = alpha + beta_user[u] + beta_item[i]\n",
    "        \n",
    "        # Compute the error\n",
    "        error = r_ui - pred\n",
    "        \n",
    "        # Update biases with regularization\n",
    "        beta_user[u] += learning_rate * (error - lambda_reg * beta_user[u])\n",
    "        beta_item[i] += learning_rate * (error - lambda_reg * beta_item[i])\n",
    "    \n",
    "    # Optionally, compute training error to monitor convergence\n",
    "    train_preds = alpha + beta_user[train_users] + beta_item[train_items]\n",
    "    train_mse = np.mean((train_preds - train_ratings) ** 2)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training MSE: {train_mse:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "3077e0fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3.2398653 , 4.06944739, 2.8043906 , 3.59557855, 3.96076233,\n",
       "       4.04303731, 3.27807296, 3.86294484, 3.44672752, 3.73284454])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_users = df_valid['user_idx'].values\n",
    "valid_items = df_valid['item_idx'].values\n",
    "valid_ratings = df_valid['rating'].values\n",
    "\n",
    "# Predict ratings\n",
    "valid_preds = alpha + beta_user[valid_users] + beta_item[valid_items]\n",
    "valid_preds[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "28be32bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation MSE: 1.4715\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(valid_ratings, valid_preds)\n",
    "print(f\"Validation MSE: {mse:.4f}\")\n",
    "validMSE = mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "422ab930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Q1': 0.7199,\n",
       " 'Q2': [0.7, 0.75095],\n",
       " 'Q3': 0.70575,\n",
       " 'Q4': 0.73175,\n",
       " 'Q5': 'I confirm that I have uploaded an assignment submission to gradescope',\n",
       " 'Q6': 1.4714928214620557}"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answers['Q6'] = validMSE\n",
    "answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "5509bf2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q6'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9826cdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "45e86d3f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'u88024921'"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "maxBeta = float(max(beta_user))\n",
    "minBeta = float(min(beta_user))\n",
    "#\n",
    "max_beta_index = np.argmax(beta_user)\n",
    "max_user_id = user_encoder.inverse_transform([max_beta_index])[0]\n",
    "maxUser = max_user_id\n",
    "\n",
    "min_beta_index = np.argmin(beta_user)\n",
    "min_user_id = user_encoder.inverse_transform([min_beta_index])[0]\n",
    "minUser = min_user_id\n",
    "minUser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c61b675c",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q7'] = [maxUser, minUser, maxBeta, minBeta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "7aca2bc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert [type(x) for x in answers['Q7']] == [str, str, float, float]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "0a416949",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ae54cf47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Training MSE: 1.2733\n",
      "Epoch 2/10, Training MSE: 1.2547\n",
      "Epoch 3/10, Training MSE: 1.2397\n",
      "Epoch 4/10, Training MSE: 1.2273\n",
      "Epoch 5/10, Training MSE: 1.2152\n",
      "Epoch 6/10, Training MSE: 1.2071\n",
      "Epoch 7/10, Training MSE: 1.1982\n",
      "Epoch 8/10, Training MSE: 1.1912\n",
      "Epoch 9/10, Training MSE: 1.1849\n",
      "Epoch 10/10, Training MSE: 1.1802\n",
      "Validation MSE: 1.4260\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 0.01\n",
    "num_epochs = 10\n",
    "lambda_reg = 0.5  # reg parameter\n",
    "\n",
    "train_users = df_train['user_idx'].values\n",
    "train_items = df_train['item_idx'].values\n",
    "train_ratings = df_train['rating'].values\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    shuffled_indices = np.arange(len(train_ratings))\n",
    "    np.random.shuffle(shuffled_indices)\n",
    "    \n",
    "    for idx in shuffled_indices:\n",
    "        u = train_users[idx]\n",
    "        i = train_items[idx]\n",
    "        r_ui = train_ratings[idx]\n",
    "        \n",
    "        # make rating predictions\n",
    "        pred = alpha + beta_user[u] + beta_item[i]\n",
    "        \n",
    "        # Compute the error\n",
    "        error = r_ui - pred\n",
    "        \n",
    "        # Update biases with regularization\n",
    "        beta_user[u] += learning_rate * (error - lambda_reg * beta_user[u])\n",
    "        beta_item[i] += learning_rate * (error - lambda_reg * beta_item[i])\n",
    "    \n",
    "    # Optionally, compute training error to monitor convergence\n",
    "    train_preds = alpha + beta_user[train_users] + beta_item[train_items]\n",
    "    train_mse = np.mean((train_preds - train_ratings) ** 2)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Training MSE: {train_mse:.4f}\")\n",
    "    \n",
    "valid_preds = alpha + beta_user[valid_users] + beta_item[valid_items]\n",
    "mse = mean_squared_error(valid_ratings, valid_preds)\n",
    "print(f\"Validation MSE: {mse:.4f}\")\n",
    "validMSE = mse\n",
    "lamb = lambda_reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f1880fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers['Q8'] = (lamb, validMSE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "56b09160",
   "metadata": {},
   "outputs": [],
   "source": [
    "assertFloat(answers['Q8'][0])\n",
    "assertFloat(answers['Q8'][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "b9bd53b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create mappings from userID/itemID to indices\n",
    "userID_to_idx = {label: idx for idx, label in enumerate(user_encoder.classes_)}\n",
    "itemID_to_idx = {label: idx for idx, label in enumerate(item_encoder.classes_)}\n",
    "\n",
    "predictions = open(\"predictions_Rating.csv\", 'w')\n",
    "for l in open(\"pairs_Rating.csv\"):\n",
    "    if l.startswith(\"userID\"): # header\n",
    "        predictions.write(l)\n",
    "        continue\n",
    "    u,b = l.strip().split(',') # Read the user and item from the \"pairs\" file and write out your prediction\n",
    "    \n",
    "    # Map userID and itemID to indices\n",
    "    if u in userID_to_idx:\n",
    "        u_idx = userID_to_idx[u]\n",
    "        beta_u = beta_user[u_idx]\n",
    "    else:\n",
    "        # Handle unseen user\n",
    "        beta_u = 0.0  # or use np.mean(beta_user)\n",
    "    \n",
    "    if b in itemID_to_idx:\n",
    "        b_idx = itemID_to_idx[b]\n",
    "        beta_i = beta_item[b_idx]\n",
    "    else:\n",
    "        # Handle unseen item\n",
    "        beta_i = 0.0  # or use np.mean(beta_item)\n",
    "    \n",
    "    # Compute the prediction\n",
    "    pred = alpha + beta_u + beta_i\n",
    "    \n",
    "    # Clip the prediction to the valid rating range (e.g., 1 to 5)\n",
    "    pred = min(max(pred, 1), 5)\n",
    "    \n",
    "    # Write out your prediction\n",
    "    predictions.write(f\"{u},{b},{pred}\\n\")\n",
    "    \n",
    "predictions.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "839261ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"answers_hw3.txt\", 'w')\n",
    "f.write(str(answers) + '\\n')\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3000bdde",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
